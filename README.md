# Logseq RAG

RAG System for Logseq Knowledge Base.

## Welcome to Logseq RAG System with Multi-LLM Support!
        
This enhanced system allows you to ask questions about your personal knowledge base using various LLM providers.

### Supported LLM Providers
- OpenAI: GPT-3.5, GPT-4, and other OpenAI models
- Anthropic: Claude-3 Sonnet, Opus, and Haiku

### Enhanced Features
- Page-based embeddings: Use complete pages instead of fine-grained blocks for better context
- Multi-LLM support: Switch between different providers
- Hybrid search modes: Combine content and title search for better results
- Search preview: See what pages are retrieved before generating answers
- ChromaDB support: Advanced vector database backend

### Quick Setup Guide
1. Clone the repository and install dependencies
2. Configure your Logseq API settings
3. Set up your preferred LLM provider
4. Initialize the RAG system
5. Start exploring your knowledge base

### Getting Started
1. Choose your LLM provider in the sidebar
2. Configure API keys and model settings
3. Set your Logseq path and vector store options
4. Configure database retrieval settings
5. Initialize the system to build embeddings
6. Start asking questions with advanced search filters




